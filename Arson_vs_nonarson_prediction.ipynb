{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CMIL7CwyOUJi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_path = 'Datasets/fe_scaled_one_hot_full_2.csv'"
   ],
   "outputs": [],
   "metadata": {
    "id": "Y8fIafBbLZWn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_fe_scaled_one_hot_full = pd.read_csv(data_path)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MHVJ03pAONK4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "columns = df_fe_scaled_one_hot_full.columns"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "kNR1aqhXOXdv",
    "outputId": "cec77464-3e76-460c-a4fd-f598d67780a2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "columns_set1 = ['FIRE_YEAR','DISCOVERY_DATE','DISCOVERY_DOY','DISCOVERY_TIME','LATITUDE','LONGITUDE',\n",
    "                'SOURCE_SYSTEM_TYPE_FED','SOURCE_SYSTEM_TYPE_INTERAGCY','SOURCE_SYSTEM_TYPE_NONFED',\n",
    "                'NWCG_REPORTING_AGENCY_BIA','NWCG_REPORTING_AGENCY_BLM','NWCG_REPORTING_AGENCY_BOR',\n",
    "                'NWCG_REPORTING_AGENCY_DOD','NWCG_REPORTING_AGENCY_DOE','NWCG_REPORTING_AGENCY_FS',\n",
    "                'NWCG_REPORTING_AGENCY_FWS','NWCG_REPORTING_AGENCY_IA','NWCG_REPORTING_AGENCY_NPS',\n",
    "                'NWCG_REPORTING_AGENCY_ST/C&L','NWCG_REPORTING_AGENCY_TRIBE','FIRE_SIZE_CLASS_A','FIRE_SIZE_CLASS_B',\n",
    "                'FIRE_SIZE_CLASS_C','FIRE_SIZE_CLASS_D','FIRE_SIZE_CLASS_E','FIRE_SIZE_CLASS_F','FIRE_SIZE_CLASS_G',\n",
    "                'OWNER_DESCR_BIA','OWNER_DESCR_BLM','OWNER_DESCR_BOR','OWNER_DESCR_COUNTY','OWNER_DESCR_FOREIGN',\n",
    "                'OWNER_DESCR_FWS','OWNER_DESCR_MISSING/NOT SPECIFIED','OWNER_DESCR_MUNICIPAL/LOCAL','OWNER_DESCR_NPS',\n",
    "                'OWNER_DESCR_OTHER FEDERAL','OWNER_DESCR_PRIVATE','OWNER_DESCR_STATE','OWNER_DESCR_STATE OR PRIVATE',\n",
    "                'OWNER_DESCR_TRIBAL','OWNER_DESCR_UNDEFINED FEDERAL','OWNER_DESCR_USFS','STATE_AK', 'STATE_AL', \n",
    "                'STATE_AR', 'STATE_AZ', 'STATE_CA', 'STATE_CO', 'STATE_CT', 'STATE_DC', 'STATE_DE', 'STATE_FL', \n",
    "                'STATE_GA', 'STATE_HI', 'STATE_IA', 'STATE_ID', 'STATE_IL', 'STATE_IN', 'STATE_KS', 'STATE_KY', \n",
    "                'STATE_LA', 'STATE_MA', 'STATE_MD', 'STATE_ME', 'STATE_MI', 'STATE_MN', 'STATE_MO', 'STATE_MS', \n",
    "                'STATE_MT', 'STATE_NC', 'STATE_ND', 'STATE_NE', 'STATE_NH', 'STATE_NJ', 'STATE_NM', 'STATE_NV', \n",
    "                'STATE_NY', 'STATE_OH', 'STATE_OK', 'STATE_OR', 'STATE_PA', 'STATE_PR', 'STATE_RI', 'STATE_SC', \n",
    "                'STATE_SD', 'STATE_TN', 'STATE_TX', 'STATE_UT', 'STATE_VA', 'STATE_VT', 'STATE_WA', 'STATE_WI', \n",
    "                'STATE_WV', 'STATE_WY']\n",
    "# DISCOVERY_TIME,Discovery_DOY,LATITUDE,LONGITUTE, all state columns, \n",
    "\n",
    "columns_set2 = ['FIRE_YEAR','DISCOVERY_DATE','lat_lon_dist','lat_lon_angle',\n",
    "                'SOURCE_SYSTEM_TYPE_FED','SOURCE_SYSTEM_TYPE_INTERAGCY','SOURCE_SYSTEM_TYPE_NONFED',\n",
    "                'NWCG_REPORTING_AGENCY_BIA','NWCG_REPORTING_AGENCY_BLM','NWCG_REPORTING_AGENCY_BOR',\n",
    "                'NWCG_REPORTING_AGENCY_DOD','NWCG_REPORTING_AGENCY_DOE','NWCG_REPORTING_AGENCY_FS',\n",
    "                'NWCG_REPORTING_AGENCY_FWS','NWCG_REPORTING_AGENCY_IA','NWCG_REPORTING_AGENCY_NPS',\n",
    "                'NWCG_REPORTING_AGENCY_ST/C&L','NWCG_REPORTING_AGENCY_TRIBE','FIRE_SIZE_CLASS_A','FIRE_SIZE_CLASS_B',\n",
    "                'FIRE_SIZE_CLASS_C','FIRE_SIZE_CLASS_D','FIRE_SIZE_CLASS_E','FIRE_SIZE_CLASS_F','FIRE_SIZE_CLASS_G',\n",
    "                'OWNER_DESCR_BIA','OWNER_DESCR_BLM','OWNER_DESCR_BOR','OWNER_DESCR_COUNTY','OWNER_DESCR_FOREIGN',\n",
    "                'OWNER_DESCR_FWS','OWNER_DESCR_MISSING/NOT SPECIFIED','OWNER_DESCR_MUNICIPAL/LOCAL','OWNER_DESCR_NPS',\n",
    "                'OWNER_DESCR_OTHER FEDERAL','OWNER_DESCR_PRIVATE','OWNER_DESCR_STATE','OWNER_DESCR_STATE OR PRIVATE',\n",
    "                'OWNER_DESCR_TRIBAL','OWNER_DESCR_UNDEFINED FEDERAL','OWNER_DESCR_USFS','DISCOVERY_TIME_BIN_A', \n",
    "                'DISCOVERY_TIME_BIN_E', 'DISCOVERY_TIME_BIN_EM','DISCOVERY_TIME_BIN_LN', 'DISCOVERY_TIME_BIN_M',\n",
    "                'DISCOVERY_TIME_BIN_N','DISCOVERY_DOY_BIN_FALL','DISCOVERY_DOY_BIN_SPRING','DISCOVERY_DOY_BIN_SUMMER',\n",
    "                'DISCOVERY_DOY_BIN_WINTER', 'REGION_East','REGION_Mid_West', 'REGION_Mountain_West',\n",
    "                'REGION_North_East','REGION_North_West', 'REGION_Pacific_West', 'REGION_South','REGION_South_East']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for column in df_fe_scaled_one_hot_full.columns:\n",
    "  if df_fe_scaled_one_hot_full[column].isna().sum()!=0:\n",
    "    print(column) #no column with na values...good!"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "woYcWC3L220Z"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#do not need below lines because we are choosing columns according to the requirements from above cell\n",
    "# df_dropped_state = df_fe_scaled_one_hot_full.copy()\n",
    "# state_columns = [col for col in df_dropped_state.columns if 'state_' in col.lower()]\n",
    "# df_dropped_state = df_dropped_state.drop(columns = state_columns)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "W6CoAg3QOlWB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# X = df_fe_scaled_one_hot_full[columns_set1]\n",
    "X2 = df_fe_scaled_one_hot_full[columns_set2]\n",
    "Y = df_fe_scaled_one_hot_full['STAT_CAUSE_DESCR_Arson']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(len(Y))\n",
    "print(sum(Y))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1880465\n",
      "281455\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only 15% of the data is labelled 1. So, let us use F1 score as accuracy metric to account for data imbalance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, check the baselines once again with the normal data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "x_train,x_valid,y_train,y_valid = train_test_split(X,Y,test_size = 0.2)\n",
    "# x_train2,x_valid2,y_train,y_valid = train_test_split(X2,Y,test_size = 0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "histgb = HistGradientBoostingClassifier().fit(x_train, y_train)\n",
    "y_pred = histgb.predict(x_valid)\n",
    "accuracy = accuracy_score(y_valid,y_pred)\n",
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8725634351078058"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "RFC = RandomForestClassifier(max_depth=50, random_state=0,bootstrap=True, n_jobs = -1).fit(x_train, y_train)\n",
    "y_pred = RFC.predict(x_valid)\n",
    "accuracy = accuracy_score(y_valid,y_pred)\n",
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8879745169412885"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "MLP_classifier = MLPClassifier(solver = 'lbfgs',alpha = 1e-2, hidden_layer_sizes = (64,32,32),\n",
    "                               random_state = 1,verbose=False, max_iter=200,activation = 'relu')\n",
    "MLP_classifier.fit(x_train,y_train)\n",
    "y_pred= MLP_classifier.predict(x_valid)\n",
    "accuracy = accuracy_score(y_valid,y_pred)\n",
    "accuracy\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/rishitajain/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8686388738955524"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now checking how the baselines look like with feature engineered data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "histgb = HistGradientBoostingClassifier().fit(x_train2, y_train)\n",
    "y_pred = histgb.predict(x_valid2)\n",
    "accuracy = accuracy_score(y_valid,y_pred)\n",
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8696093785313739"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "RFC = RandomForestClassifier(max_depth=50, random_state=0,bootstrap=True, n_jobs =-1).fit(x_train2, y_train)\n",
    "y_pred = RFC.predict(x_valid2)\n",
    "accuracy = accuracy_score(y_valid,y_pred)\n",
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8821355356254968"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We will not be using MLP with feature engineering data by assuming that feature engineering is not needed for MLP\n",
    "# MLP_classifier = MLPClassifier(solver = 'lbfgs',alpha = 1e-2, hidden_layer_sizes = (64,32,32),\n",
    "#                                random_state = 1,verbose=False, max_iter=200,activation = 'relu')\n",
    "# MLP_classifier.fit(x_train2,y_train)\n",
    "# y_pred= MLP_classifier.predict(x_valid)\n",
    "# accuracy = accuracy_score(y_valid,y_pred)\n",
    "# accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will do grid search cv to find best parameters for each of the below classifiers\n",
    "First, grid search cv for histGradientBoostClassifier\n",
    "Second, RandomForestClassifier\n",
    "Third, Neural Network\n",
    "Fourth, ExtraTreesClassifier\n",
    "Fifth, Decision Tree CV with VotingClassifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# X = df_dropped_state.copy()\n",
    "# cause_columns = [col for col in df_dropped_state.columns if 'stat_cause_' in col.lower()]\n",
    "# X = X.drop(columns = cause_columns)\n",
    "# Y = df_dropped_state['STAT_CAUSE_DESCR_Arson']"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Fp44xMGQQ624"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# histgb = HistGradientBoostingClassifier(max_depth=50).fit(x_train, y_train)\n",
    "# y_pred = histgb.predict(x_valid)\n",
    "# accuracy = accuracy_score(y_valid,y_pred)\n",
    "# accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8701189291339994"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghYL45BJ2c16",
    "outputId": "b30e3594-43a2-42fc-f81d-f848b503f532"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "# parameters = {#'loss':['log_loss', 'auto', 'binary_crossentropy', 'categorical_crossentropy'],\n",
    "#                 'loss':['binary_crossentropy'],\n",
    "# #               'learning_rate':[0.001,0.005,0.01,0.05,0.1,0.2,0.3,0.4,0.5]},\n",
    "#                 'learning_rate':[0.2],\n",
    "# #                 'max_leaf_nodes':[5,10,15,20,25,30,35,40,45,50]}\n",
    "#                 'max_leaf_nodes':[45],\n",
    "# #               'max_iter':[100],\n",
    "# #               'max_depth':[5,10,15,20,25,30,35,40,50,60,70,None]}\n",
    "#                 'max_depth':[70],\n",
    "# #               'min_samples_leaf':[5,10,15,20,25,30,35,40,50,60,80,100]}\n",
    "#                 'min_samples_leaf':[100]}\n",
    "# #               'l2_regularization':[0]}\n",
    "# parameters"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': ['binary_crossentropy'],\n",
       " 'learning_rate': [0.2],\n",
       " 'max_leaf_nodes': [45],\n",
       " 'max_depth': [70],\n",
       " 'min_samples_leaf': [35]}"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "m6UBd88cFOPh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "# histgb = HistGradientBoostingClassifier()\n",
    "# # clf = GridSearchCV(histgb, parameters)\n",
    "# histgb_results = clf.fit(x_train,y_train)"
   ],
   "outputs": [],
   "metadata": {
    "id": "qYejBr95Jre4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "# histgb_result = pd.DataFrame.from_dict(histgb_results.cv_results_)\n",
    "# histgb_result[histgb_result['rank_test_score']==1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.281308</td>\n",
       "      <td>0.486512</td>\n",
       "      <td>0.0987</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>0.2</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'binary_crossen...</td>\n",
       "      <td>0.850263</td>\n",
       "      <td>0.850263</td>\n",
       "      <td>0.850263</td>\n",
       "      <td>0.850263</td>\n",
       "      <td>0.850263</td>\n",
       "      <td>0.850263</td>\n",
       "      <td>2.438086e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       6.281308      0.486512           0.0987        0.013356   \n",
       "\n",
       "  param_learning_rate           param_loss param_max_depth  \\\n",
       "0                 0.2  binary_crossentropy              70   \n",
       "\n",
       "  param_max_leaf_nodes param_min_samples_leaf  \\\n",
       "0                   45                     35   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.2, 'loss': 'binary_crossen...           0.850263   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.850263           0.850263           0.850263           0.850263   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.850263    2.438086e-07                1  "
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "metadata": {
    "id": "2VfpfKqMKls9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "# histgb = HistGradientBoostingClassifier(loss='binary_crossentropy',learning_rate=0.2,max_leaf_nodes=45,\n",
    "#                                         max_depth=70,min_samples_leaf=100)\n",
    "# histgb.fit(x_train,y_train)\n",
    "# y_pred = histgb.predict(x_valid)\n",
    "# accuracy = accuracy_score(y_valid,y_pred)\n",
    "# accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8505821698356524"
      ]
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#hist gradient boosting classifier on feature engineered data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "source": [
    "# parameters = {#'loss':['log_loss', 'auto', 'binary_crossentropy', 'categorical_crossentropy'],\n",
    "#                 'loss':['binary_crossentropy'],\n",
    "# #               'learning_rate':[0.001,0.005,0.01,0.05,0.1,0.2,0.3,0.4,0.5]},\n",
    "#                 'learning_rate':[0.5],\n",
    "# #                 'max_leaf_nodes':[5,10,15,20,25,30,35,40,45,50]}\n",
    "#                 'max_leaf_nodes':[300],\n",
    "# #               'max_iter':[100],\n",
    "# #               'max_depth':[5,10,15,20,25,30,35,40,50,60,70,None]}\n",
    "#                 'max_depth':[100],\n",
    "# #               'min_samples_leaf':[5,10,15,20,25,30,35,40,50,60,80,100]}\n",
    "#                 'min_samples_leaf':[120]}\n",
    "# #               'l2_regularization':[0]}\n",
    "# parameters"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': ['binary_crossentropy'],\n",
       " 'learning_rate': [0.5],\n",
       " 'max_leaf_nodes': [300],\n",
       " 'max_depth': [100],\n",
       " 'min_samples_leaf': [120]}"
      ]
     },
     "metadata": {},
     "execution_count": 230
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "source": [
    "# histgb = HistGradientBoostingClassifier()\n",
    "# clf = GridSearchCV(histgb, parameters)\n",
    "# histgb_results = clf.fit(x_train2,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "# histgb_result = pd.DataFrame.from_dict(histgb_results.cv_results_)\n",
    "# histgb_result[histgb_result['rank_test_score']==1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.226817</td>\n",
       "      <td>2.016156</td>\n",
       "      <td>0.713377</td>\n",
       "      <td>0.047181</td>\n",
       "      <td>0.5</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>120</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'binary_crossen...</td>\n",
       "      <td>0.881017</td>\n",
       "      <td>0.882067</td>\n",
       "      <td>0.880754</td>\n",
       "      <td>0.880781</td>\n",
       "      <td>0.880365</td>\n",
       "      <td>0.880997</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      28.226817      2.016156         0.713377        0.047181   \n",
       "\n",
       "  param_learning_rate           param_loss param_max_depth  \\\n",
       "4                 0.5  binary_crossentropy             100   \n",
       "\n",
       "  param_max_leaf_nodes param_min_samples_leaf  \\\n",
       "4                  300                    120   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "4  {'learning_rate': 0.5, 'loss': 'binary_crossen...           0.881017   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "4           0.882067           0.880754           0.880781           0.880365   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "4         0.880997        0.000575                1  "
      ]
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "# histgb = HistGradientBoostingClassifier(loss='binary_crossentropy',learning_rate=0.5,max_leaf_nodes=300,\n",
    "#                                         max_depth=100,min_samples_leaf=120)\n",
    "# histgb.fit(x_train2,y_train)\n",
    "# y_pred = histgb.predict(x_valid2)\n",
    "# accuracy = accuracy_score(y_valid,y_pred)\n",
    "# accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.88260616390095"
      ]
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# x_train,x_valid,y_train,y_valid = train_test_split(X,Y,test_size = 0.1)\n",
    "x_train2,x_valid2,y_train,y_valid = train_test_split(X2,Y,test_size = 0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#RandomForestClassifier on normal data #baseline is 0.887"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "parameters = {\n",
    "    'criterion':['entropy'], #0.871\n",
    "    'max_depth' : [100],\n",
    "    'bootstrap' : [True], #871\n",
    "#     'max_depth':[20],\n",
    "    'min_samples_split':[15,20],#0.872\n",
    "    'min_samples_leaf':[1,5],\n",
    "    'max_features':['sqrt', 'log2', None, 0.7, 0.8],\n",
    "    'n_jobs':[-1]\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "rfc_result = pd.DataFrame.from_dict(rfc_results.cv_results_)\n",
    "rfc_result[rfc_result['rank_test_score']==1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.454661</td>\n",
       "      <td>0.23337</td>\n",
       "      <td>0.165987</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'entropy', 'm...</td>\n",
       "      <td>0.876416</td>\n",
       "      <td>0.876413</td>\n",
       "      <td>0.877343</td>\n",
       "      <td>0.874658</td>\n",
       "      <td>0.875269</td>\n",
       "      <td>0.87602</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "13      19.454661       0.23337         0.165987        0.012336   \n",
       "\n",
       "   param_bootstrap param_criterion param_max_depth param_max_features  \\\n",
       "13            True         entropy             100                0.7   \n",
       "\n",
       "   param_min_samples_leaf param_min_samples_split param_n_jobs  \\\n",
       "13                      1                      20           -1   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "13  {'bootstrap': True, 'criterion': 'entropy', 'm...           0.876416   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "13           0.876413           0.877343           0.874658   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "13           0.875269          0.87602        0.000947                1  "
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the final model on normal dataset"
   ],
   "metadata": {
    "id": "UMghzsteTugf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "RFC = RandomForestClassifier(criterion='entropy',max_depth=100,bootstrap=True,min_samples_split=5,min_samples_leaf=1,\n",
    "                            max_features=0.7,n_jobs=-1,random_state=0)\n",
    "\n",
    "RFC.fit(x_train,y_train)\n",
    "\n",
    "y_pred = RFC.predict(x_valid)\n",
    "accuracy = accuracy_score(y_valid,y_pred)"
   ],
   "outputs": [],
   "metadata": {
    "id": "WDCQVgGZStvl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8926438603115179"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "f1score = f1_score(y_valid,y_pred,average='weighted')\n",
    "f1score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8836866046622843"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "parameters = {\n",
    "    'criterion':['gini'], #0.871\n",
    "    'max_depth' : [30],\n",
    "    'bootstrap' : [True], #871\n",
    "#     'max_depth':[20],\n",
    "    'min_samples_split':[10],#0.872\n",
    "    'min_samples_leaf':[1],\n",
    "    'max_features':['sqrt', 'log2', None, 0.7, 0.8, 0.9],\n",
    "    'n_jobs':[-1]\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC_clf = GridSearchCV(RFC, parameters, verbose = 3)\n",
    "rfc_results = RFC_clf.fit(x_train2,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "rfc_result = pd.DataFrame.from_dict(rfc_results.cv_results_)\n",
    "rfc_result[rfc_result['rank_test_score']==1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.209311</td>\n",
       "      <td>0.221306</td>\n",
       "      <td>0.156824</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>0.874661</td>\n",
       "      <td>0.877769</td>\n",
       "      <td>0.875562</td>\n",
       "      <td>0.878061</td>\n",
       "      <td>0.876173</td>\n",
       "      <td>0.876445</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3      13.209311      0.221306         0.156824          0.0033   \n",
       "\n",
       "  param_bootstrap param_criterion param_max_depth param_max_features  \\\n",
       "3            True            gini              30                0.7   \n",
       "\n",
       "  param_min_samples_leaf param_min_samples_split param_n_jobs  \\\n",
       "3                      1                      10           -1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'bootstrap': True, 'criterion': 'gini', 'max_...           0.874661   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.877769           0.875562           0.878061           0.876173   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.876445        0.001296                1  "
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "RFC = RandomForestClassifier(criterion='gini',max_depth=30,bootstrap=True,min_samples_split=10,min_samples_leaf=1,\n",
    "                            max_features=0.7,n_jobs=-1,random_state=0)\n",
    "\n",
    "RFC.fit(x_train2,y_train)\n",
    "\n",
    "y_pred = RFC.predict(x_valid2)\n",
    "accuracy = accuracy_score(y_valid,y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8925375039218919"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "f1score = f1_score(y_valid,y_pred,average='weighted')\n",
    "f1score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8822642878092349"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "grid_search_cv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}